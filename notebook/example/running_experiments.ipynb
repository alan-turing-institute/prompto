{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch processing pipeline\n",
    "\n",
    "## Running experiments\n",
    "\n",
    "When running the pipeline, there are a few key classes that we will look at in this notebook:\n",
    "- `Settings`: this defines the settings of the the experiment pipeline which stores the paths to the relevant data folders and the parameters for the pipeline.\n",
    "- `Experiment`: this defines all the variables related to a _single_ experiment. An 'experiment' here is defined by a particular JSONL file which contains the data/prompts for each experiment. Each line in this folder is a particular input to the LLM which we will obtain a response for.\n",
    "- `ExperimentPipeline`: this is the main class for running the full pipeline. The pipeline can be ran using the `ExperimentPipeline.run()` method which will continually check the input folder for new experiments to process.\n",
    "    - This takes in a `Settings` object and for each JSONL file in the input folder, it will create an `Experiment` object and run the experiments sequentially as they are created in the input folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_llm.settings import Settings\n",
    "from batch_llm.experiment_processing import Experiment, ExperimentPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "The `Settings` class stores all the relevant information for the pipeline such as the paths to the data folders, the maximum number of queries per minute, and the number of max retries for failed requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings(data_folder=\"data\", max_queries=50, max_attempts=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the settings object to see the current settings easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: data_folder=data, max_queries=50, max_attempts=5\n",
      "Subfolders: input_folder=data/input, output_folder=data/output, media_folder=data/media\n"
     ]
    }
   ],
   "source": [
    "print(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will just print out the attributes of the settings object to see what is stored in it (although we have just printed these above as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settings.data_folder: data\n",
      "settings.input_folder: data/input\n",
      "settings.output_folder: data/output\n",
      "settings.media_folder: data/media\n",
      "settings.max_queries: 50\n",
      "settings.max_attempts: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"settings.data_folder: {settings.data_folder}\")\n",
    "print(f\"settings.input_folder: {settings.input_folder}\")\n",
    "print(f\"settings.output_folder: {settings.output_folder}\")\n",
    "print(f\"settings.media_folder: {settings.media_folder}\")\n",
    "print(f\"settings.max_queries: {settings.max_queries}\")\n",
    "print(f\"settings.max_attempts: {settings.max_attempts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `input_folder`, `output_folder` and `media_folder` attributes are read only (by using the `@property` decorator) and so we cannot change these directly. This is because we want to have consistency with the `data_folder` attribute.\n",
    "\n",
    "So if we try to change the `input_folder, `output_folder` and `media_folder` attributes, it will raise an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "WriteFolderError",
     "evalue": "Cannot write to input folder on it's own. Use the 'set_and_create_subfolders' method to set the input folder.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWriteFolderError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_folder\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_folder/input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/batch-llm/src/batch_llm/settings.py:87\u001b[0m, in \u001b[0;36mSettings.input_folder\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;129m@input_folder\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput_folder\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WriteFolderError(\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot write to input folder on it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms own. Use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_and_create_subfolders\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod to set the input folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m     )\n",
      "\u001b[0;31mWriteFolderError\u001b[0m: Cannot write to input folder on it's own. Use the 'set_and_create_subfolders' method to set the input folder."
     ]
    }
   ],
   "source": [
    "settings.input_folder = \"unknown_folder/input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "WriteFolderError",
     "evalue": "Cannot write to output folder on it's own. Use the 'set_and_create_subfolders' method to set the output folder.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWriteFolderError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_folder\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_folder/output\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/batch-llm/src/batch_llm/settings.py:100\u001b[0m, in \u001b[0;36mSettings.output_folder\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;129m@output_folder\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moutput_folder\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WriteFolderError(\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot write to output folder on it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms own. Use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_and_create_subfolders\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod to set the output folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m     )\n",
      "\u001b[0;31mWriteFolderError\u001b[0m: Cannot write to output folder on it's own. Use the 'set_and_create_subfolders' method to set the output folder."
     ]
    }
   ],
   "source": [
    "settings.output_folder = \"unknown_folder/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "WriteFolderError",
     "evalue": "Cannot write to media folder on it's own. Use the 'set_and_create_subfolders' method to set the media folder.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWriteFolderError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedia_folder\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_folder/media\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/batch-llm/src/batch_llm/settings.py:113\u001b[0m, in \u001b[0;36mSettings.media_folder\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;129m@media_folder\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedia_folder\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WriteFolderError(\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot write to media folder on it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms own. Use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_and_create_subfolders\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod to set the media folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n",
      "\u001b[0;31mWriteFolderError\u001b[0m: Cannot write to media folder on it's own. Use the 'set_and_create_subfolders' method to set the media folder."
     ]
    }
   ],
   "source": [
    "settings.media_folder = \"unknown_folder/media\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What really is happening under the hood is we're using a `@property` dectorator and we do not define a setter method for these attributes. This means that we cannot change these attributes directly. Of course, we can change the underlying `_input_folder`, `_output_folder` and `_media_folder` attributes directly if we want to change these, but this is not recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings._input_folder = \"unknown_folder/input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unknown_folder/input'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.input_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the `data_folder` attribute to a new path if we want to change the data folder. When doing so, it will check if the folder exists, otherwise we get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data folder unknown_folder does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_folder\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_folder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/batch-llm/src/batch_llm/settings.py:73\u001b[0m, in \u001b[0;36mSettings.data_folder\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;129m@data_folder\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_folder\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# check the data folder exists\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_folder_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# set the data folder\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_folder \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/batch-llm/src/batch_llm/settings.py:44\u001b[0m, in \u001b[0;36mSettings.check_folder_exists\u001b[0;34m(data_folder)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# check if data folder exists\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(data_folder):\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData folder \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Data folder unknown_folder does not exist."
     ]
    }
   ],
   "source": [
    "settings.data_folder = \"unknown_folder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the data does exist, it will store the new path and importantly, this will also update the `input_folder`, `output_folder` and `media_folder` attributes accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.data_folder = \"data2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the `input_folder`, `output_folder` and `media_folder` attributes have been updated to the new corresponding paths.\n",
    "\n",
    "We also create these subfolders if they do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: data_folder=data2, max_queries=50, max_attempts=5\n",
      "Subfolders: input_folder=data2/input, output_folder=data2/output, media_folder=data2/media\n"
     ]
    }
   ],
   "source": [
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settings.data_folder: data2\n",
      "settings.input_folder: data2/input\n",
      "settings.output_folder: data2/output\n",
      "settings.media_folder: data2/media\n",
      "settings.max_queries: 50\n",
      "settings.max_attempts: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"settings.data_folder: {settings.data_folder}\")\n",
    "print(f\"settings.input_folder: {settings.input_folder}\")\n",
    "print(f\"settings.output_folder: {settings.output_folder}\")\n",
    "print(f\"settings.media_folder: {settings.media_folder}\")\n",
    "print(f\"settings.max_queries: {settings.max_queries}\")\n",
    "print(f\"settings.max_attempts: {settings.max_attempts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "The `Experiment` class stores all the relevant information for a single experiment. To initialise, we need to pass in the path to the JSONL file which contains the data for the experiment.\n",
    "\n",
    "The `Experiment` class stores several attributes:\n",
    "- `file_name`: the name of the JSONL file\n",
    "- `experiment_name`: the file_name without the `.jsonl` extension\n",
    "- `settings`: `Settings` object which is described above\n",
    "- `output_folder`: the path to the output folder _for the experiment_, e.g. `data_folder/output_folder/experiment_name`\n",
    "- `creation_time`: the time the experiment file was created\n",
    "- `log_file`: the path to the log file for the experiment, e.g. `data_folder/output_folder/experiment_name/{creation_time}_experiment_name.log`\n",
    "- `input_file_path`: the path to the input JSONL file, e.g. `data_folder/input_folder/experiment_name.jsonl`\n",
    "- `output_completed_file_path`: the path to the completed output JSONL file, e.g. `data_folder/output_folder/experiment_name/completed-experiment_name.jsonl`\n",
    "- `output_input_file_path`: the path to the input output JSONL file, e.g. `data_folder/output_folder/experiment_name/input-experiment_name.jsonl` (this is just for logging to know what the input to the experiment was)\n",
    "\n",
    "Essentially, when initialising an `Experiment` object, we construct all the paths that are relevant to that particular experiment such as the log file, the input file path, and the file paths for storing the final output for the experiment. \n",
    "\n",
    "We construct these paths by using the `Settings` object which tells us where all the paths to the relevant folders are.\n",
    "\n",
    "Finally, `Experiment` also stores:\n",
    "- `experiment_prompts` as a list of dictionaries (we just read in the JSONL to get these)\n",
    "- `number_queries`: the number of queries in the experiment (i.e. the length of `experiment_prompts`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\"test.jsonl\", settings=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08-04-2024-09-46'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.creation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 9,\n",
       "  'prompt': ['Hello',\n",
       "   \"My name is Bob and I'm 6 years old\",\n",
       "   'How old am I next year?'],\n",
       "  'model': 'gdm-b',\n",
       "  'parameters': {'candidate_count': 1,\n",
       "   'max_output_tokens': 64,\n",
       "   'temperature': 1,\n",
       "   'top_k': 40}},\n",
       " {'id': 10,\n",
       "  'prompt': ['Can you give me a random number between 1-10?',\n",
       "   'What is +5 of that number?',\n",
       "   'What is half of that number?'],\n",
       "  'model': 'gdm-b',\n",
       "  'parameters': {'candidate_count': 1,\n",
       "   'max_output_tokens': 128,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 40}},\n",
       " {'id': 11,\n",
       "  'prompt': \"How many theaters are there in London's South End?\",\n",
       "  'model': 'gdm-b'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.experiment_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.number_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out all the relevant information for the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment.file_name: test.jsonl\n",
      "experiment.input_file_path: data2/input/test.jsonl\n",
      "experiment.output_folder: data2/output/test\n",
      "experiment.output_input_file_out_path: data2/output/test/input-test.jsonl\n",
      "experiment.output_completed_file_path: data2/output/test/completed-test.jsonl\n",
      "experiment.log_file: data2/output/test/08-04-2024-09-46-log.txt\n"
     ]
    }
   ],
   "source": [
    "print(f\"experiment.file_name: {experiment.file_name}\")\n",
    "print(f\"experiment.input_file_path: {experiment.input_file_path}\")\n",
    "print(f\"experiment.output_folder: {experiment.output_folder}\")\n",
    "print(f\"experiment.output_input_file_out_path: {experiment.output_input_file_out_path}\")\n",
    "print(f\"experiment.output_completed_file_path: {experiment.output_completed_file_path}\")\n",
    "print(f\"experiment.log_file: {experiment.log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the object just prints out the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.jsonl\n"
     ]
    }
   ],
   "source": [
    "print(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.jsonl'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{experiment}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Pipeline\n",
    "\n",
    "The `ExperimentPipeline` class is the main class for running the full pipeline which will continually check the input folder for new experiments to process. To initialise, it simply just takes in a `Settings` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ExperimentPipeline(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It stores several things such as:\n",
    "- `settings`: `Settings` object\n",
    "- `average_per_query_processing_times`: this is a list of the average query processing times for each experiment\n",
    "- `overall_avg_proc_times`: this is a float which is an average of the values in `average_per_query_processing_times`\n",
    "\n",
    "These last two attributes are just for logging purposes to see how long each experiment takes on average and for us to give a very rough estimate of how long we may expect queries to return to us.\n",
    "\n",
    "The object will also store `experiment_files` which is a list of all the JSONL files in the input folder. When the pipeline is running, it will check this folder for new experiments to process and order then by creation time so that we process the oldest experiments first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline.settings: Settings: data_folder=data2, max_queries=50, max_attempts=5\n",
      "Subfolders: input_folder=data2/input, output_folder=data2/output, media_folder=data2/media\n",
      "pipeline.average_per_query_processing_times: []\n",
      "pipeline.overall_avg_proc_times: 0.0\n",
      "pipeline.experiment_files: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"pipeline.settings: {pipeline.settings}\")\n",
    "print(\n",
    "    f\"pipeline.average_per_query_processing_times: {pipeline.average_per_query_processing_times}\"\n",
    ")\n",
    "print(f\"pipeline.overall_avg_proc_times: {pipeline.overall_avg_proc_times}\")\n",
    "print(f\"pipeline.experiment_files: {pipeline.experiment_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class has several methods but two key ones that are important are:\n",
    "- `run()`: this is the main method which will continually check the input folder for new experiments to process. When processing experiments, we create an `Experiment` object as described above, and process the experiment.\n",
    "- `process_experiment(experiment: Experiment)`: this processes a single experiment. It will loop through each query in the experiment and send it to the LLM to get a response. It will then store the response in the output file in the relevant output folder for the experiment.\n",
    "\n",
    "Here, we won't run the pipeline, but you can start one from the CLI using the `run_pipeline.py` script, or just use the `run_pipeline` CLI command. This takes in three arguments:\n",
    "1. `--data-folder`: the path to the data folder\n",
    "2. `--max-queries`: the maximum number of queries per minute\n",
    "3. `--max-attempts`: the maximum number of attempts for each query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending 3 queries:   0%|          | 0/3 [00:00<?, ?query/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending 3 queries: 100%|██████████| 3/3 [00:03<00:00,  1.20s/query]\n",
      "Waiting for responses: 100%|██████████| 3/3 [00:00<00:00, 323.20query/s]\n"
     ]
    }
   ],
   "source": [
    "await pipeline.process_experiment(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the experiment has finished and we have a new updated query processing estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline.average_per_query_processing_times: []\n",
      "pipeline.overall_avg_proc_times: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"pipeline.average_per_query_processing_times: {pipeline.average_per_query_processing_times}\"\n",
    ")\n",
    "print(f\"pipeline.overall_avg_proc_times: {pipeline.overall_avg_proc_times}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the output, we can see we got errors that there were `KeyErrors` as the model was not implemented. To see the models implemented, there is a dictionary of models in the `models` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': batch_llm.models.testing.testing_model.TestModel,\n",
       " 'gemini': batch_llm.models.gemini.gemini.Gemini}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from batch_llm.models import MODELS\n",
    "\n",
    "MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run one with `gemini` models and for this, we must set environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GEMINI_PROJECT_ID\"] = \"gdm-model-evals-turing\"\n",
    "os.environ[\"GEMINI_MODEL_NAME\"] = \"gdm-eval-model-a\"\n",
    "os.environ[\"GEMINI_LOCATION\"] = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending 3 queries:   0%|          | 0/3 [00:00<?, ?query/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending 3 queries: 100%|██████████| 3/3 [00:03<00:00,  1.20s/query]\n",
      "Waiting for responses: 100%|██████████| 3/3 [00:00<00:00, 299.94query/s]\n"
     ]
    }
   ],
   "source": [
    "experiment2 = Experiment(\"test2.jsonl\", settings=settings)\n",
    "await pipeline.process_experiment(experiment2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batch-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
