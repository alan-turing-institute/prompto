[tool.poetry]
name = "batch-llm"
version = "0.1.0"
description = "Library for facilitating batch processing of experiments stored as jsonl files. by automating querying LLM APIs and logging progress"
authors = ["rchan <rchan@turing.ac.uk>",
           "fedenanni <nanni.federico@gmail.com>",
           "evelinag <evelina@evelinag.com>"]
readme = "README.md"

[tool.poetry.dependencies]
python = ">=3.11"
transformers = "^4.39.3"
torch = "^2.2.2"
accelerate = "^0.28.0"
fastapi = "^0.110.1"
uvicorn = "^0.29.0"
tqdm = "^4.66.2"
black = {version = "^24.3.0", optional=true }
isort = {version = "^5.13.2", optional=true }
pre-commit = {version = "^3.7.0", optional=true }
ipykernel = {version = "^6.29.4", optional=true }
pytest = {version = "^8.1.1",   optional=true }
vertexai = {version = "^1.46.0", optional=true }
google-cloud-aiplatform = {version = "^1.46.0", optional=true }
google-generativeai = {version = "^0.4.1", optional=true }
pillow = "^10.3.0"
openai = {version = "^1.19.0", optional=true }


[tool.poetry.extras]
dev = ["black", "isort", "pre-commit", "ipykernel", "pytest"]
test = ["pytest"]
gemini = ["vertexai", "google-cloud-aiplatform", "google-generativeai"]
azure_openai = ["openai"]
openai = ["openai"]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
run_pipeline = "batch_llm.scripts.run_pipeline:main"
run_checks = "batch_llm.scripts.run_checks:main"
create_judge_file = "batch_llm.scripts.create_judge_file:main"
obtain_missing_jsonl = "batch_llm.scripts.obtain_missing_jsonl:main"
convert_images = "batch_llm.scripts.convert_images:main"
