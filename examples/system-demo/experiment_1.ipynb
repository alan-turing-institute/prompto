{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async `Prompto` vs. Python for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import send_gemini, send_openai, send_ollama, send_prompt\n",
    "from dataset_utils import load_prompt_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_prompts(prompt_dicts: list[dict]) -> list[str]:\n",
    "    # maive for loop to synchronously dispatch prompts\n",
    "    for prompt_dict in prompt_dicts:\n",
    "        send_prompt(prompt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dicts = load_prompt_dicts(\"./data/input/openai-gpt-3.5.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'api': 'openai',\n",
       "  'model_name': 'gpt-3.5-turbo',\n",
       "  'prompt': 'How does technology impact us?',\n",
       "  'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 100}},\n",
       " {'id': 0,\n",
       "  'api': 'openai',\n",
       "  'model_name': 'gpt-3.5-turbo',\n",
       "  'prompt': 'What is the North Pole?',\n",
       "  'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 100}},\n",
       " {'id': 0,\n",
       "  'api': 'openai',\n",
       "  'model_name': 'gpt-3.5-turbo',\n",
       "  'prompt': 'What is the capital of France?',\n",
       "  'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 100}}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_prompts(prompt_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_test = send_ollama(prompt=\"Hello, world!\", model_name=\"llama3\", params={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_test = send_gemini(\n",
    "    prompt=\"Hello, world!\", model_name=\"gemini-1.5-flash\", params={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_test = send_openai(prompt=\"Hello, world!\", model_name=\"gpt-3.5-turbo\", params={})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
