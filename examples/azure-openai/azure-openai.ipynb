{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `prompto` with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompto.settings import Settings\n",
    "from prompto.experiment import Experiment\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `prompto` to query models from the OpenAI API, lines in our experiment `.jsonl` files must have `\"api\": \"openai\"` in the prompt dict. \n",
    "\n",
    "## Environment variables\n",
    "\n",
    "For the [AzureOpenAI API](../../docs/models.md#azure-openai), there are four environment variables that could be set:\n",
    "- `AZURE_OPENAI_API_KEY`: the API key for the Azure OpenAI API\n",
    "- `AZURE_OPENAI_API_ENDPOINT`: the endpoint for the Azure OpenAI API\n",
    "- `AZURE_OPENAI_API_VERSION`: the version of the Azure OpenAI API (optional)\n",
    "- `AZURE_OPENAI_MODEL_NAME`: the default model name for the Azure OpenAI API (optional)\n",
    "\n",
    "As mentioned in the [model docs](../../docs/models.md#model-specific-environment-variables), there are also model-specific environment variables too which can be utilised. In particular, if you specify a `model_name` key in a prompt dict, one could also specify a `AZURE_OPENAI_API_KEY_model_name` environment variable to indicate the API key used for that particular model (where \"model_name\" is replaced to whatever the corresponding value of the `model_name` key is). We will see a concrete example of this later. The same applies for the `AZURE_OPENAI_API_ENDPOINT_model_name` and `AZURE_OPENAI_API_VERSION_model_name` environment variables.\n",
    "\n",
    "Note that `OPENAI_MODEL_NAME` is optional since you can simply specify `model_name` to each prompt dict that has `\"api\": \"azure-openai\"`.\n",
    "\n",
    "To set environment variables, one can simply have these in a `.env` file which specifies these environment variables as key-value pairs:\n",
    "```\n",
    "AZURE_OPENAI_API_KEY = <YOUR-AZURE-OPENAI-KEY>\n",
    "AZURE_OPENAI_API_ENDPOINT = <YOUR-AZURE-OPENAI-ENDPOINT>\n",
    "AZURE_OPENAI_API_VERSION = <DEFAULT-AZURE-OPENAI-API-VERSION>\n",
    "AZURE_OPENAI_MODEL_NAME = <DEFAULT-AZURE-OPENAI-MODEL>\n",
    "```\n",
    "\n",
    "If you make this file, you can run the following which should return `True` if it's found one, or `False` otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path=\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we obtain those values. We raise an error if the `OPENAI_API_KEY` environment variable hasn't been set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "if AZURE_OPENAI_API_KEY is None:\n",
    "    raise ValueError(\"AZURE_OPENAI_API_KEY is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_API_ENDPOINT = os.environ.get(\"AZURE_OPENAI_API_ENDPOINT\")\n",
    "if AZURE_OPENAI_API_ENDPOINT is None:\n",
    "    raise ValueError(\"AZURE_OPENAI_API_ENDPOINT is not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only raise a warning if `AZURE_OPENAI_API_VERSION` or `AZURE_OPENAI_MODEL_NAME` hasn't been set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default AzureOpenAI version: 2024-02-01\n"
     ]
    }
   ],
   "source": [
    "AZURE_OPENAI_API_VERSION = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "if AZURE_OPENAI_API_VERSION is None:\n",
    "    warnings.warn(\"AZURE_OPENAI_API_VERSION is not set\")\n",
    "else:\n",
    "    print(f\"Default AzureOpenAI version: {AZURE_OPENAI_API_VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the model name for the AzureOpenAI API is actually the _deployment name_ of the model that you have chosen in your Azure subscription. For us, we set this to be \"reginald-gpt4\", but you should replace this with your own deployment name of whatever model you have chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default AzureOpenAI model: reginald-gpt4\n"
     ]
    }
   ],
   "source": [
    "AZURE_OPENAI_MODEL_NAME = os.environ.get(\"AZURE_OPENAI_MODEL_NAME\")\n",
    "if AZURE_OPENAI_MODEL_NAME is None:\n",
    "    warnings.warn(\"AZURE_OPENAI_MODEL_NAME is not set\")\n",
    "else:\n",
    "    print(f\"Default AzureOpenAI model: {AZURE_OPENAI_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get any errors or warnings in the above two cells, try to fix your `.env` file like the example we have above to get these variables set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "With the OpenAI API, the prompt (given via the `\"prompt\"` key in the prompt dict) can take several forms:\n",
    "- a string: a single prompt to obtain a response for\n",
    "- a list of strings: a sequence of prompts to send to the model\n",
    "    - this is useful in the use case of simulating a conversation with the model by defining the user prompts sequentially\n",
    "- a list of dictionaries with keys \"role\" and \"content\", where \"role\" is one of \"user\", \"assistant\", or \"system\" and \"content\" is the message\n",
    "    - this is useful in the case of passing in some conversation history or to pass in a system prompt to the model\n",
    "\n",
    "We have created an input file in [data/input/azure-openai-example.jsonl](./data/input/azure-openai-example.jsonl) with an example of each of these cases as an illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings(data_folder=\"./data\", max_queries=30)\n",
    "experiment = Experiment(file_name=\"azure-openai-example.jsonl\", settings=settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set `max_queries` to 30 so we send 30 queries a minute (every 2 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: data_folder=./data, max_queries=30, max_attempts=3, parallel=False\n",
      "Subfolders: input_folder=./data/input, output_folder=./data/output, media_folder=./data/media\n"
     ]
    }
   ],
   "source": [
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(experiment.experiment_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the prompts that we have in the `experiment_prompts` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'api': 'azure-openai',\n",
       "  'prompt': 'How does technology impact us?',\n",
       "  'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 1000}},\n",
       " {'id': 1,\n",
       "  'api': 'azure-openai',\n",
       "  'model_name': 'gpt-3.5-turbo',\n",
       "  'prompt': 'How does technology impact us?',\n",
       "  'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 1000}},\n",
       " {'id': 2,\n",
       "  'api': 'azure-openai',\n",
       "  'prompt': ['How does international trade create jobs?',\n",
       "   'I want a joke about that'],\n",
       "  'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 1000}},\n",
       " {'id': 3,\n",
       "  'api': 'azure-openai',\n",
       "  'prompt': [{'role': 'system',\n",
       "    'content': 'You are a helpful assistant designed to answer questions briefly.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'What efforts are being made to keep the hakka language alive?'}],\n",
       "  'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 1000}},\n",
       " {'id': 4,\n",
       "  'api': 'azure-openai',\n",
       "  'prompt': [{'role': 'system',\n",
       "    'content': 'You are a helpful assistant designed to answer questions briefly.'},\n",
       "   {'role': 'user', 'content': \"Hello, I'm Bob and I'm 6 years old\"},\n",
       "   {'role': 'assistant', 'content': 'Hi Bob, how may I assist you?'},\n",
       "   {'role': 'user', 'content': 'How old will I be next year?'}],\n",
       "  'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 1000}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.experiment_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the first prompt (`\"id\": 0`), we have a `\"prompt\"` key which is a string and we do not specify a `\"model_name\"` key, hence we will use the model specified by the `AZURE_OPENAI_MODEL_NAME` environment variable.\n",
    "- In the second prompt (`\"id\": 1`), we have a `\"prompt\"` key is also a string but we specify a `\"model_name\"` key to be \"gpt-3.5-turbo\" which will override the default model specified by the `AZURE_OPENAI_MODEL_NAME` environment variable. We also will first look to see if there is a `AZURE_OPENAI_API_KEY_gpt_3_5_turbo` environment variable set since we look for model-specific environment variables whenever a `model_name` key is specified. Here, we don't do that, so we will use the `OPENAI_API_KEY` environment variable.\n",
    "- In the third prompt (`\"id\": 2`), we have a `\"prompt\"` key which is a list of strings. Like the first prompt, we also do not specify a `\"model_name\"` key, so we will use the model specified by the `AZURE_OPENAI_MODEL_NAME` environment variable.\n",
    "- In the fourth prompt (`\"id\": 3`), we have a `\"prompt\"` key which is a list of dictionaries. These dictionaries have a \"role\" and \"content\" key. This acts as passing in a system prompt. Here, we just have a system prompt before a user prompt. No `\"model_name\"` key is specified.\n",
    "- In the fifth prompt (`\"id\": 4`), we have a `\"prompt\"` key which is a list of dictionaries. These dictionaries have a \"role\" and \"content\" key. Here, we have a system prompt and a series of user/assistant interactions before finally having a user prompt. This acts as passing in a system prompt and conversation history. No `\"model_name\"` key is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a helpful assistant designed to answer questions briefly.'},\n",
       " {'role': 'user',\n",
       "  'content': 'What efforts are being made to keep the hakka language alive?'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.experiment_prompts[3][\"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the experiment\n",
    "\n",
    "We now can run the experiment using the async method `process` which will process the prompts in the input file asynchronously. Note that a new folder named `timestamp-openai-example` (where \"timestamp\" is replaced with the actual date and time of processing) will be created in the output directory and we will move the input file to the output directory. As the responses come in, they will be written to the output file and there are logs that will be printed to the console as well as being written to a log file in the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending 5 queries  (attempt 1/3): 100%|██████████| 5/5 [00:10<00:00,  2.00s/query]\n",
      "Waiting for responses  (attempt 1/3): 100%|██████████| 5/5 [01:00<00:00, 12.17s/query]\n",
      "Sending 1 queries  (attempt 2/3): 100%|██████████| 1/1 [00:02<00:00,  2.00s/query]\n",
      "Waiting for responses  (attempt 2/3): 100%|██████████| 1/1 [00:00<00:00, 12.49query/s]\n",
      "Sending 1 queries  (attempt 3/3): 100%|██████████| 1/1 [00:02<00:00,  2.01s/query]\n",
      "Waiting for responses  (attempt 3/3): 100%|██████████| 1/1 [00:00<00:00, 12.76query/s]\n"
     ]
    }
   ],
   "source": [
    "responses = await experiment.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the responses are written to the output file, and we can also see them as the returned object. From running the experiment, we obtain prompt dicts where there is now a `\"response\"` key which contains the response(s) from the model.\n",
    "\n",
    "For the case where the prompt is a list of strings, we see that the response is a list of strings where each string is the response to the corresponding prompt.\n",
    "\n",
    "Note here, for our specific Azure subscription, we haven't got a model with deployment name \"gpt-3.5-turbo\" and hence, we actually receive an error message in the response for the second prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'id': 4,\n",
       "   'api': 'azure-openai',\n",
       "   'prompt': [{'role': 'system',\n",
       "     'content': 'You are a helpful assistant designed to answer questions briefly.'},\n",
       "    {'role': 'user', 'content': \"Hello, I'm Bob and I'm 6 years old\"},\n",
       "    {'role': 'assistant', 'content': 'Hi Bob, how may I assist you?'},\n",
       "    {'role': 'user', 'content': 'How old will I be next year?'}],\n",
       "   'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 1000},\n",
       "   'response': \"If you're 6 years old now, you'll be 7 years old next year.\"},\n",
       "  {'id': 3,\n",
       "   'api': 'azure-openai',\n",
       "   'prompt': [{'role': 'system',\n",
       "     'content': 'You are a helpful assistant designed to answer questions briefly.'},\n",
       "    {'role': 'user',\n",
       "     'content': 'What efforts are being made to keep the hakka language alive?'}],\n",
       "   'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 1000},\n",
       "   'response': 'Efforts to keep the Hakka language alive include a range of cultural, educational, and technological initiatives:\\n\\n1. **Language Education**: Courses and programs at various educational levels, from primary schools to universities, aiming to teach the Hakka language and encourage its use among younger generations.\\n   \\n2. **Media and Entertainment**: Hakka TV channels, radio stations, and online platforms that produce content in Hakka, such as news, dramas, and music, to increase exposure to the language.\\n\\n3. **Literature and Publishing**: Promotion of Hakka literature through publishing books, poetry, and research in the language to enrich its written forms.\\n\\n4. **Cultural Festivals and Events**: Organization of festivals and events celebrating Hakka culture, which helps to foster a sense of pride and community among Hakka speakers.\\n\\n5. **Language Preservation Projects**: Recording and documenting the spoken language, especially by capturing the narratives of older speakers, to preserve different dialects and vocabulary.\\n\\n6. **Advocacy and Policy**: Lobbying for government policies that support Hakka language education and broadcasting, plus official recognition of Hakka as a minority language in certain regions.\\n\\n7. **Technology and Apps**: Development of smartphone apps, online courses, and social media content that facilitate the learning and regular use of Hakka.\\n\\n8. **Community Initiatives**: Local community efforts, such as language clubs and conversation groups where Hakka speakers can practice and maintain their language skills.\\n\\n9. **Research and Academic Study**: Academic research into the Hakka language, which helps to deepen the understanding of its structure, history, and development.\\n\\n10. **International Collaboration**: Building connections with the global Hakka diaspora to share resources and strategies for language preservation and to create a broader sense of solidarity.\\n\\nThese efforts are crucial to preserve the Hakka language and prevent it from becoming endangered or extinct, especially in the face of dominant languages and globalization.'},\n",
       "  {'id': 0,\n",
       "   'api': 'azure-openai',\n",
       "   'prompt': 'How does technology impact us?',\n",
       "   'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 1000},\n",
       "   'response': 'Technology impacts us in numerous ways across all facets of life. Here are several key areas where technology plays a significant role:\\n\\n1. Communication: Technology has revolutionized the way we communicate. With the advent of smartphones, social media, and instant messaging apps, people can stay connected with others from any corner of the globe in real-time.\\n\\n2. Access to Information: The internet provides vast amounts of information on virtually any topic at the click of a button. This ready access to knowledge helps in education, research, and decision-making.\\n\\n3. Entertainment: Technology has changed how we consume entertainment, with services like streaming platforms allowing us to watch movies and series or listen to music anytime and anywhere.\\n\\n4. Health and Medicine: Advancements in medical technology have dramatically improved diagnostics, treatment options, and patient care, leading to improved health outcomes and longer life expectancies.\\n\\n5. Productivity and Efficiency: Automation and digital tools have increased productivity in the workplace. They allow for more efficient workflows, data management, and time-saving on tasks that were once labor-intensive.\\n\\n6. Education: Educational technology facilitates a variety of learning experiences, providing interactive and personalized learning environments, distance education, and access to online courses.\\n\\n7. Job Creation and Economic Growth: While technology can make certain jobs obsolete, it also creates new markets and job opportunities, often leading to economic growth and innovation.\\n\\n8. Environmental Impact: Technology can both positively and negatively affect the environment. It enables renewable energy innovations and efficient resource management but also contributes to electronic waste and energy consumption.\\n\\n9. Social Interaction: Technology has influenced the way we socialize, creating new forms of online communities, but it can also contribute to social isolation and the deterioration of traditional social skills for some individuals.\\n\\n10. Surveillance and Privacy: Technology has raised significant concerns regarding privacy, with the ability to collect, analyze, and use vast amounts of personal data. This has implications for personal privacy, as well as potential uses in government surveillance.\\n\\n11. Transportation and Travel: Advancements in transportation technology, such as electric vehicles, autonomous cars, and high-speed rail, have revolutionized how we travel, potentially making it faster, more efficient, and more environmentally friendly.\\n\\n12. The Digital Divide: Not everyone has equal access to technology. Differences in socioeconomic status, geography, or education can lead to a digital divide, which can perpetuate inequalities.\\n\\nOverall, technology is a double-edged sword that brings about significant changes and requires careful consideration of its benefits and potential negative consequences. As technology continues to develop, its impact on various aspects of life is expected to grow even further.'},\n",
       "  {'id': 2,\n",
       "   'api': 'azure-openai',\n",
       "   'prompt': ['How does international trade create jobs?',\n",
       "    'I want a joke about that'],\n",
       "   'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 1000},\n",
       "   'response': [\"International trade creates jobs in a variety of ways, both directly and indirectly. Here are some of the mechanisms through which this occurs:\\n\\n1. Export Expansion:\\n   - When a country exports goods and services to other countries, it needs workers to produce, market, and deliver those products. This leads to job creation in sectors like manufacturing, agriculture, and services.\\n\\n2. Specialization and Efficiency:\\n   - International trade allows countries to specialize in the production of goods and services where they have a comparative advantage. This specialization can lead to more efficient production, increasing output and requiring more labor to meet the demand.\\n\\n3. Foreign Direct Investment (FDI):\\n   - Trade openness can attract foreign investors who want to take advantage of new markets. These investors build factories, offices, or retail outlets, creating construction jobs initially and permanent positions once the investment is operational.\\n\\n4. Supply Chain Development:\\n   - International trade fosters the development of supply chains, where different countries play roles in creating a final product. Each step in the supply chain provides job opportunities in various countries involved.\\n\\n5. Increased Consumer Choice and Demand:\\n   - Access to a wider variety of goods and services can increase consumer spending. As demand grows, companies need to hire more workers to keep up with consumer needs, resulting in job growth.\\n\\n6. Technological Transfer and Innovation:\\n   - International trade often involves the exchange of technologies and best practices, leading to innovation. This can create jobs in high-tech industries, research and development, and other areas that rely on advancements in knowledge and technology.\\n\\n7. Competitive Pressures:\\n   - Exposure to international competition prompts companies to improve their efficiency and productivity, which may involve investing in new equipment, technologies, or training for their workforce. These investments can lead to the creation of higher-skilled jobs.\\n\\n8. Service Sector Growth:\\n   - As goods are traded internationally, there's also a need for associated services such as banking, logistics, legal services, and tourism. The growth in these areas prompts job creation in the service sector.\\n\\n9. Scale Economies:\\n   - Manufacturers and service providers who export may achieve economies of scale—meaning the cost per unit of production decreases as output increases. This can make businesses more profitable, potentially leading to expansions and new hiring.\\n\\nIt's important to note that while international trade does create jobs, it can also lead to job displacement in industries that are less competitive or are negatively impacted by imports. Economies often need to adapt, and there can be transitional costs and periods of adjustment. The net effect on employment depends on a range of factors, including the nature of the trade agreements, the competitiveness of industries, and the flexibility of the labor market. Additionally, policies may be necessary to support workers in industries affected by trade, through retraining programs, education, and other assistance measures.\",\n",
       "    \"Why don't countries play hide and seek?\\n\\nBecause with international trade, the best ones are always spotted and end up drawing a crowd!\"]},\n",
       "  {'id': 1,\n",
       "   'api': 'azure-openai',\n",
       "   'model_name': 'gpt-3.5-turbo',\n",
       "   'prompt': 'How does technology impact us?',\n",
       "   'parameters': {'n': 1, 'temperature': 1, 'max_tokens': 1000},\n",
       "   'response': \"An unexpected error occurred when querying the API: NotFoundError - Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}} after maximum 3 attempts\"}],\n",
       " 15.007961988449097)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the experiment via the command line\n",
    "\n",
    "We can also run the experiment via the command line. The command is as follows (assuming that your working directory is the current directory of this notebook, i.e. `examples/azure-openai`):\n",
    "```bash\n",
    "prompto_run_experiment --file data/input/azure-openai-example.jsonl --max_queries 30\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
