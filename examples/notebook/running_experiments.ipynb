{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch processing pipeline\n",
    "\n",
    "## Running experiments\n",
    "\n",
    "When running the pipeline, there are a few key classes that we will look at in this notebook:\n",
    "- `Settings`: this defines the settings of the the experiment pipeline which stores the paths to the relevant data folders and the parameters for the pipeline.\n",
    "- `Experiment`: this defines all the variables related to a _single_ experiment. An 'experiment' here is defined by a particular JSONL file which contains the data/prompts for each experiment. Each line in this folder is a particular input to the LLM which we will obtain a response for.\n",
    "- `ExperimentPipeline`: this is the main class for running the full pipeline. The pipeline can be ran using the `ExperimentPipeline.run()` method which will continually check the input folder for new experiments to process.\n",
    "    - This takes in a `Settings` object and for each JSONL file in the input folder, it will create an `Experiment` object and run the experiments sequentially as they are created in the input folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from prompto import Settings, Experiment, ExperimentPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "The `Settings` class stores all the relevant information for the pipeline such as the paths to the data folders, the maximum number of queries per minute, and the number of max retries for failed requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"data\" not in os.listdir(\".\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings(data_folder=\"data\", max_queries=50, max_attempts=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the settings object to see the current settings easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: data_folder=data, max_queries=50, max_attempts=5, parallel=False\n",
      "Subfolders: input_folder=data/input, output_folder=data/output, media_folder=data/media\n"
     ]
    }
   ],
   "source": [
    "print(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will just print out the attributes of the settings object to see what is stored in it (although we have just printed these above as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settings.data_folder: data\n",
      "settings.input_folder: data/input\n",
      "settings.output_folder: data/output\n",
      "settings.media_folder: data/media\n",
      "settings.max_queries: 50\n",
      "settings.max_attempts: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"settings.data_folder: {settings.data_folder}\")\n",
    "print(f\"settings.input_folder: {settings.input_folder}\")\n",
    "print(f\"settings.output_folder: {settings.output_folder}\")\n",
    "print(f\"settings.media_folder: {settings.media_folder}\")\n",
    "print(f\"settings.max_queries: {settings.max_queries}\")\n",
    "print(f\"settings.max_attempts: {settings.max_attempts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `input_folder`, `output_folder` and `media_folder` attributes are read only (by using the `@property` decorator) and so we cannot change these directly. This is because we want to have consistency with the `data_folder` attribute.\n",
    "\n",
    "So if we try to change the `input_folder, `output_folder` and `media_folder` attributes, it will raise an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "WriteFolderError",
     "evalue": "Cannot set input folder on it's own. Set the 'data_folder' instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWriteFolderError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_folder\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_folder/input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/prompto/src/prompto/settings.py:137\u001b[0m, in \u001b[0;36mSettings.input_folder\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;129m@input_folder\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput_folder\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WriteFolderError(\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set input folder on it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms own. Set the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_folder\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n",
      "\u001b[0;31mWriteFolderError\u001b[0m: Cannot set input folder on it's own. Set the 'data_folder' instead"
     ]
    }
   ],
   "source": [
    "settings.input_folder = \"unknown_folder/input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "WriteFolderError",
     "evalue": "Cannot set output folder on it's own. Set the 'data_folder' instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWriteFolderError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_folder\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_folder/output\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/prompto/src/prompto/settings.py:149\u001b[0m, in \u001b[0;36mSettings.output_folder\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;129m@output_folder\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moutput_folder\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WriteFolderError(\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set output folder on it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms own. Set the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_folder\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m     )\n",
      "\u001b[0;31mWriteFolderError\u001b[0m: Cannot set output folder on it's own. Set the 'data_folder' instead"
     ]
    }
   ],
   "source": [
    "settings.output_folder = \"unknown_folder/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "WriteFolderError",
     "evalue": "Cannot set media folder on it's own. Set the 'data_folder' instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWriteFolderError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedia_folder\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_folder/media\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/prompto/src/prompto/settings.py:161\u001b[0m, in \u001b[0;36mSettings.media_folder\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;129m@media_folder\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedia_folder\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WriteFolderError(\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set media folder on it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms own. Set the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_folder\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m     )\n",
      "\u001b[0;31mWriteFolderError\u001b[0m: Cannot set media folder on it's own. Set the 'data_folder' instead"
     ]
    }
   ],
   "source": [
    "settings.media_folder = \"unknown_folder/media\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What really is happening under the hood is we're using a `@property` dectorator and we do not define a setter method for these attributes. This means that we cannot change these attributes directly. Of course, we can change the underlying `_input_folder`, `_output_folder` and `_media_folder` attributes directly if we want to change these, but this is not recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings._input_folder = \"unknown_folder/input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unknown_folder/input'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.input_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the `data_folder` attribute to a new path if we want to change the data folder. When doing so, it will check if the folder exists, otherwise we get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data folder 'unknown_folder' must be a valid path to a folder",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_folder\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_folder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/prompto/src/prompto/settings.py:123\u001b[0m, in \u001b[0;36mSettings.data_folder\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;129m@data_folder\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_folder\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# check the data folder exists\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_folder_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# set the data folder\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_folder \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/prompto/src/prompto/settings.py:75\u001b[0m, in \u001b[0;36mSettings.check_folder_exists\u001b[0;34m(data_folder)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# check if data folder exists\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(data_folder):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData folder \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a valid path to a folder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m     )\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Data folder 'unknown_folder' must be a valid path to a folder"
     ]
    }
   ],
   "source": [
    "settings.data_folder = \"unknown_folder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the data does exist, it will store the new path and importantly, this will also update the `input_folder`, `output_folder` and `media_folder` attributes accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.data_folder = \"data2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the `input_folder`, `output_folder` and `media_folder` attributes have been updated to the new corresponding paths.\n",
    "\n",
    "We also create these subfolders if they do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: data_folder=data2, max_queries=50, max_attempts=5, parallel=False\n",
      "Subfolders: input_folder=data2/input, output_folder=data2/output, media_folder=data2/media\n"
     ]
    }
   ],
   "source": [
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settings.data_folder: data2\n",
      "settings.input_folder: data2/input\n",
      "settings.output_folder: data2/output\n",
      "settings.media_folder: data2/media\n",
      "settings.max_queries: 50\n",
      "settings.max_attempts: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"settings.data_folder: {settings.data_folder}\")\n",
    "print(f\"settings.input_folder: {settings.input_folder}\")\n",
    "print(f\"settings.output_folder: {settings.output_folder}\")\n",
    "print(f\"settings.media_folder: {settings.media_folder}\")\n",
    "print(f\"settings.max_queries: {settings.max_queries}\")\n",
    "print(f\"settings.max_attempts: {settings.max_attempts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "The `Experiment` class stores all the relevant information for a single experiment. To initialise, we need to pass in the path to the JSONL file which contains the data for the experiment.\n",
    "\n",
    "The `Experiment` class stores several attributes:\n",
    "- `file_name`: the name of the JSONL file\n",
    "- `experiment_name`: the file_name without the `.jsonl` extension\n",
    "- `settings`: `Settings` object which is described above\n",
    "- `output_folder`: the path to the output folder _for the experiment_, e.g. `data_folder/output_folder/experiment_name`\n",
    "- `creation_time`: the time the experiment file was created\n",
    "- `log_file`: the path to the log file for the experiment, e.g. `data_folder/output_folder/experiment_name/{creation_time}_experiment_name.log`\n",
    "- `input_file_path`: the path to the input JSONL file, e.g. `data_folder/input_folder/experiment_name.jsonl`\n",
    "- `output_completed_file_path`: the path to the completed output JSONL file, e.g. `data_folder/output_folder/experiment_name/completed-experiment_name.jsonl`\n",
    "- `output_input_file_path`: the path to the input output JSONL file, e.g. `data_folder/output_folder/experiment_name/input-experiment_name.jsonl` (this is just for logging to know what the input to the experiment was)\n",
    "\n",
    "Essentially, when initialising an `Experiment` object, we construct all the paths that are relevant to that particular experiment such as the log file, the input file path, and the file paths for storing the final output for the experiment. \n",
    "\n",
    "We construct these paths by using the `Settings` object which tells us where all the paths to the relevant folders are.\n",
    "\n",
    "Finally, `Experiment` also stores:\n",
    "- `experiment_prompts` as a list of dictionaries (we just read in the JSONL to get these)\n",
    "- `number_queries`: the number of queries in the experiment (i.e. the length of `experiment_prompts`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\"test.jsonl\", settings=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20-05-2024-15-01-24'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.creation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 9,\n",
       "  'prompt': ['Hello',\n",
       "   \"My name is Bob and I'm 6 years old\",\n",
       "   'How old am I next year?'],\n",
       "  'api': 'unknown-model-name',\n",
       "  'parameters': {'candidate_count': 1,\n",
       "   'max_output_tokens': 64,\n",
       "   'temperature': 1,\n",
       "   'top_k': 40}},\n",
       " {'id': 10,\n",
       "  'prompt': ['Can you give me a random number between 1-10?',\n",
       "   'What is +5 of that number?',\n",
       "   'What is half of that number?'],\n",
       "  'api': 'unknown-model-name',\n",
       "  'parameters': {'candidate_count': 1,\n",
       "   'max_output_tokens': 128,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 40}},\n",
       " {'id': 11,\n",
       "  'prompt': \"How many theaters are there in London's South End?\",\n",
       "  'api': 'unknown-model-name'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.experiment_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.number_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out all the relevant information for the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment.file_name: test.jsonl\n",
      "experiment.input_file_path: data2/input/test.jsonl\n",
      "experiment.output_folder: data2/output/test\n",
      "experiment.output_input_file_out_path: data2/output/test/20-05-2024-15-01-24-input-test.jsonl\n",
      "experiment.output_completed_file_path: data2/output/test/20-05-2024-15-01-24-completed-test.jsonl\n",
      "experiment.log_file: data2/output/test/20-05-2024-15-01-24-test-log.txt\n"
     ]
    }
   ],
   "source": [
    "print(f\"experiment.file_name: {experiment.file_name}\")\n",
    "print(f\"experiment.input_file_path: {experiment.input_file_path}\")\n",
    "print(f\"experiment.output_folder: {experiment.output_folder}\")\n",
    "print(f\"experiment.output_input_file_out_path: {experiment.output_input_file_out_path}\")\n",
    "print(f\"experiment.output_completed_file_path: {experiment.output_completed_file_path}\")\n",
    "print(f\"experiment.log_file: {experiment.log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the object just prints out the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.jsonl\n"
     ]
    }
   ],
   "source": [
    "print(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.jsonl'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{experiment}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Pipeline\n",
    "\n",
    "The `ExperimentPipeline` class is the main class for running the full pipeline which will continually check the input folder for new experiments to process. To initialise, it simply just takes in a `Settings` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ExperimentPipeline(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It stores several things such as:\n",
    "- `settings`: `Settings` object\n",
    "- `average_per_query_processing_times`: this is a list of the average query processing times for each experiment\n",
    "- `overall_avg_proc_times`: this is a float which is an average of the values in `average_per_query_processing_times`\n",
    "\n",
    "These last two attributes are just for logging purposes to see how long each experiment takes on average and for us to give a very rough estimate of how long we may expect queries to return to us.\n",
    "\n",
    "The object will also store `experiment_files` which is a list of all the JSONL files in the input folder. When the pipeline is running, it will check this folder for new experiments to process and order then by creation time so that we process the oldest experiments first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline.settings: Settings: data_folder=data2, max_queries=50, max_attempts=5, parallel=False\n",
      "Subfolders: input_folder=data2/input, output_folder=data2/output, media_folder=data2/media\n",
      "pipeline.average_per_query_processing_times: []\n",
      "pipeline.overall_avg_proc_times: 0.0\n",
      "pipeline.experiment_files: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"pipeline.settings: {pipeline.settings}\")\n",
    "print(\n",
    "    f\"pipeline.average_per_query_processing_times: {pipeline.average_per_query_processing_times}\"\n",
    ")\n",
    "print(f\"pipeline.overall_avg_proc_times: {pipeline.overall_avg_proc_times}\")\n",
    "print(f\"pipeline.experiment_files: {pipeline.experiment_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class has several methods but two key ones that are important are:\n",
    "- `run()`: this is the main method which will continually check the input folder for new experiments to process. When processing experiments, we create an `Experiment` object as described above, and process the experiment.\n",
    "- `process_experiment(experiment: Experiment)`: this processes a single experiment. It will loop through each query in the experiment and send it to the LLM to get a response. It will then store the response in the output file in the relevant output folder for the experiment.\n",
    "\n",
    "Here, we won't run the pipeline, but you can start one from the CLI using the `run_pipeline.py` script, or just use the `run_pipeline` CLI command. This takes in three arguments:\n",
    "1. `--data-folder`: the path to the data folder\n",
    "2. `--max-queries`: the maximum number of queries per minute\n",
    "3. `--max-attempts`: the maximum number of attempts for each query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending 3 queries  (attempt 1/5): 100%|██████████| 3/3 [00:03<00:00,  1.20s/query]\n",
      "Waiting for responses  (attempt 1/5): 100%|██████████| 3/3 [00:00<00:00, 1450.81query/s]\n"
     ]
    }
   ],
   "source": [
    "await pipeline.process_experiment(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the experiment has finished and we have a new updated query processing estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline.average_per_query_processing_times: [1.2831729253133137]\n",
      "pipeline.overall_avg_proc_times: 1.2831729253133137\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"pipeline.average_per_query_processing_times: {pipeline.average_per_query_processing_times}\"\n",
    ")\n",
    "print(f\"pipeline.overall_avg_proc_times: {pipeline.overall_avg_proc_times}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the output, we can see we got errors that there were `KeyErrors` as the model was not implemented. To see the models implemented, there is a dictionary of models in the `models` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': prompto.apis.testing.testing_api.AsyncTestAPI,\n",
       " 'azure-openai': prompto.apis.azure_openai.azure_openai.AsyncAzureOpenAIAPI,\n",
       " 'openai': prompto.apis.openai.openai.AsyncOpenAIAPI,\n",
       " 'gemini': prompto.apis.gemini.gemini.AsyncGeminiAPI,\n",
       " 'ollama': prompto.apis.ollama.ollama.AsyncOllamaAPI,\n",
       " 'huggingface-tgi': prompto.apis.huggingface_tgi.huggingface_tgi.AsyncHuggingfaceTGIAPI,\n",
       " 'quart': prompto.apis.quart.quart.AsyncQuartAPI}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prompto.apis import ASYNC_APIS\n",
    "\n",
    "ASYNC_APIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run one with `test` models which is a class we've created that will just respond with `\"This is a test response\"` each time or it will give an error with probability 1/5These prompts are given in the `\"test2.jsonl\"` file in the input folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 9,\n",
       "  'prompt': ['Hello',\n",
       "   \"My name is Bob and I'm 6 years old\",\n",
       "   'How old am I next year?'],\n",
       "  'api': 'test',\n",
       "  'parameters': {'candidate_count': 1,\n",
       "   'max_output_tokens': 64,\n",
       "   'temperature': 1,\n",
       "   'top_k': 40}},\n",
       " {'id': 10,\n",
       "  'prompt': ['Can you give me a random number between 1-10?',\n",
       "   'What is +5 of that number?',\n",
       "   'What is half of that number?'],\n",
       "  'api': 'test',\n",
       "  'parameters': {'candidate_count': 1,\n",
       "   'max_output_tokens': 128,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 40}},\n",
       " {'id': 11,\n",
       "  'prompt': \"How many theaters are there in London's South End?\",\n",
       "  'api': 'test'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment2 = Experiment(\"test2.jsonl\", settings=settings)\n",
    "experiment2.experiment_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending 3 queries  (attempt 1/5): 100%|██████████| 3/3 [00:03<00:00,  1.20s/query]\n",
      "Waiting for responses  (attempt 1/5): 100%|██████████| 3/3 [00:15<00:00,  5.00s/query]\n"
     ]
    }
   ],
   "source": [
    "await pipeline.process_experiment(experiment2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
